---

title: "Week 2"
excerpt: "First Steps II"

---

Whats I have done this second week is the following: 
* Read more documentation (other TFMs from previous years).
* I have learned how every exercise from Robotics-Academy runs inside the docker container. For every exercise there are a pair of files: 
    - **exercise.py**. A program in Python.  
    - **exercise.html**. A web page. 
    
  These two files are connected through a WebSocket, which is a connection between a client and server and provides a bidirectional,   full-duplex communications channel that operates over HTTP through a single TCP/IP socket connection. 
  
  The advantages of this design are these two:
    - Doing computer vision and robotic exercises without the need of installing any program (all dependencies are already installed      inside the docker). 
    - Docker is multiplatform. 

  The browser offers two things: a text editor and a graphic interface. 
  
  Focusing on the exercise.py, it has four parts:
    - **HAL** (Hardware Abstraction Layer). This layer allows the computer to interact with a hardware devide. In our case, this hardware      devide will be mainly the camera/webcam. 
    - **Brain.** This is basically the 'brain' of the robot and here is where the image processing takes place. 
    - **GUI** (Graphical user interface). This offers methods such as 'GUI.showImage()'. This part sends the image(received from the        brain) to the browser through another websocket.
    - **Management.** This part basically receives the source code written by the user and runs it on the brain. 
